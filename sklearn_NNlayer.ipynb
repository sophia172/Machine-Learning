{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The purpose of the script is testing, no confidential data envolved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 1. Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 2. Import data sets and separate training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris training data has  120  samples and  4  features\n",
      ".... result should look like this... \n",
      " [1 0 1 0 0 2 0 0 2 1 0 0 0 2 0 2 0 2 1 0 0 1 2 2 1 1 0 2 1 2 1 2 2 1 0 2 2\n",
      " 1 2 1 0 0 2 2 2 2 0 1 0 0 1 2 2 1 1 0 2 2 0 1 0 1 1 0 0 0 1 2 0 2 1 1 2 2\n",
      " 0 2 0 1 1 2 2 0 1 0 0 1 1 2 1 1 2 2 2 0 1 1 1 0 0 1 2 1 2 2 0 0 2 1 2 1 1\n",
      " 1 0 1 0 0 2 2 0 1] \n",
      "\n",
      ">>>\n",
      ">>>\n",
      "\n",
      "digits training data has  1437  samples and  64  features\n",
      ".... result should look like this... \n",
      " [3 2 2 ... 5 1 5] \n",
      "\n",
      ">>>\n",
      ">>>\n",
      "\n",
      "wine training data has  1279  samples and  11  features\n",
      ".... result should look like this... \n",
      " [5. 7. 6. ... 6. 6. 6.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()\n",
    "wine_dataset_url = 'http://mlr.cs.umass.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "wine = np.genfromtxt(wine_dataset_url, delimiter=';',skip_header=1)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(iris.data,iris.target,\n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=123, \n",
    "                                                        stratify=iris.target)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(digits.data,digits.target,\n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=123, \n",
    "                                                        stratify=digits.target)\n",
    "\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(wine[:,:-1], wine[:,-1],\n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=123, \n",
    "                                                        stratify= wine[:,-1])\n",
    "\n",
    "\n",
    "print('iris training data has ',np.shape(X1_train)[0], ' samples and ',\n",
    "      np.shape(X1_train)[1], ' features')\n",
    "print('.... result should look like this... \\n', y1_train, '\\n')\n",
    "\n",
    "print('>>>\\n>>>\\n')\n",
    "\n",
    "print('digits training data has ',np.shape(X2_train)[0], ' samples and ',\n",
    "      np.shape(X2_train)[1], ' features')\n",
    "print('.... result should look like this... \\n', y2_train, '\\n')\n",
    "\n",
    "print('>>>\\n>>>\\n')\n",
    "\n",
    "\n",
    "print('wine training data has ',np.shape(X3_train)[0], ' samples and ',\n",
    "      np.shape(X3_train)[1], ' features')\n",
    "print('.... result should look like this... \\n', y3_train, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 3. Declare data preprocessing steps\n",
    "    I am setting up to algorithm here, one is Random Forest Regression, the other one is neural network for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need all the processor to start working\n",
    "pipeline_RF = make_pipeline(preprocessing.StandardScaler(), \n",
    "                             RandomForestRegressor(n_estimators=100,n_jobs=-1)) \n",
    "\n",
    "\n",
    "\n",
    "pipeline_NN = make_pipeline(preprocessing.StandardScaler(),\n",
    "                             MLPClassifier(max_iter=500,solver='lbfgs', \n",
    "                                           alpha=1e-5,\n",
    "                                           hidden_layer_sizes=(5, 2), \n",
    "                                           random_state=1,\n",
    "                                           n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 4. Declare hyperparameters to tune\n",
    "    Does NN-layer need hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters_RF = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}\n",
    "\n",
    "hyperparameters_NN = [{'mlpclassifier__hidden_layer_sizes': [(5,5,5), (5,10,5), (10)],\n",
    "#                       'mlpclassifier__activation' : [‘identity’, ‘logistic’, ‘tanh’, ‘relu’],\n",
    "#                       'mlpclassifier__solver': ['sgd', 'adam'],\n",
    "#                       'mlpclassifier__alpha': [0.0001, 0.05],\n",
    "                      'mlpclassifier__learning_rate': ['constant','adaptive']}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 5.Tune model using cross-validation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('randomforestregressor',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_...\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=100,\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'randomforestregressor__max_depth': [None, 5, 3, 1],\n",
       "                         'randomforestregressor__max_features': ['auto', 'sqrt',\n",
       "                                                                 'log2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_RF = GridSearchCV(pipeline_RF, hyperparameters_RF, cv=10)\n",
    "\n",
    "\n",
    "clf_RF.fit(X1_train, y1_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('mlpclassifier',\n",
       "                                        MLPClassifier(activation='relu',\n",
       "                                                      alpha=1e-05,\n",
       "                                                      batch_size='auto',\n",
       "                                                      beta_1=0.9, beta_2=0.999,\n",
       "                                                      early_stopping=False,\n",
       "                                                      epsilon=1e-08,\n",
       "                                                      hidden_layer_sizes=(5, 2),\n",
       "                                                      learning_rate='constant',...\n",
       "                                                      random_state=1,\n",
       "                                                      shuffle=True,\n",
       "                                                      solver='lbfgs',\n",
       "                                                      tol=0.0001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=False,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'mlpclassifier__hidden_layer_sizes': [(5, 5, 5),\n",
       "                                                                (5, 10, 5),\n",
       "                                                                10],\n",
       "                          'mlpclassifier__learning_rate': ['constant',\n",
       "                                                           'adaptive']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NN = GridSearchCV(pipeline_NN, hyperparameters_NN, cv=5)\n",
    "\n",
    "\n",
    "clf_NN.fit(X3_train, y3_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 6. Evaluate model pipeline on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01782458  0.00863636 -0.01448808 -0.02851361  0.00863636  0.\n",
      " -0.00301081  0.37374388 -0.40906423  0.          0.          0.94185652\n",
      " -0.09918731  0.05319917 -0.01448808  0.18262909  0.          0.\n",
      "  0.          0.01888889  0.         -0.00897906 -0.165471    0.22868205\n",
      " -0.00301081 -0.05870514  0.03420399  0.08744556  0.06791715  0.04358048]\n",
      "[1.01782458 0.00863636 1.98551192 1.97148639 0.00863636 0.\n",
      " 1.99698919 1.37374388 1.59093577 0.         0.         1.94185652\n",
      " 1.90081269 1.05319917 1.98551192 1.18262909 0.         0.\n",
      " 0.         0.01888889 0.         1.99102094 1.834529   1.22868205\n",
      " 1.99698919 1.94129486 1.03420399 1.08744556 1.06791715 1.04358048]\n"
     ]
    }
   ],
   "source": [
    "pred = clf_RF.predict(X1_test)\n",
    "print(pred-y1_test)\n",
    "print(pred)\n",
    "\n",
    "# pred = clf_NN.predict(X1_test)\n",
    "# prob_est = clf_NN.predict_proba(X1_test)\n",
    "# print(prob_est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 7. Check the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, valid_scores = learning_curve(clf_NN, \n",
    "                                                         X3_train, y3_train, \n",
    "                                                         train_sizes=[0.1, 0.33, 0.55, 0.78, 1. ], \n",
    "                                                         cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # 10. Save model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf_RF, 'rf_regressor.pkl')\n",
    "joblib.dump(clf_NN, 'rf_regressor.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
